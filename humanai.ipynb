{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (2.1.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from scikit-learn) (2.1.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.14.1-cp311-cp311-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jeff/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class RecommendationModel():\n",
    "    def __init__(self):\n",
    "        # Data Preparation\n",
    "        spotify_df = pd.read_csv('data.csv')\n",
    "        data_w_genre = pd.read_csv('data_w_genres.csv')\n",
    "        data_w_genre['genres_upd'] = data_w_genre['genres'].apply(lambda x: [re.sub(' ','_',i) for i in re.findall(r\"'([^']*)'\", x)])\n",
    "        spotify_df['artists_upd_v1'] = spotify_df['artists'].apply(lambda x: re.findall(r\"'([^']*)'\", x))\n",
    "        spotify_df['artists_upd_v2'] = spotify_df['artists'].apply(lambda x: re.findall('\\\"(.*?)\\\"',x))\n",
    "        spotify_df['artists_upd'] = np.where(spotify_df['artists_upd_v1'].apply(lambda x: not x), spotify_df['artists_upd_v2'], spotify_df['artists_upd_v1'])\n",
    "        spotify_df['artists_song'] = spotify_df.apply(lambda row: row['artists_upd'][0]+row['name'],axis=1)\n",
    "        spotify_df.sort_values(['artists_song','release_date'], ascending=False, inplace=True)\n",
    "        spotify_df.drop_duplicates('artists_song', inplace=True)\n",
    "        artists_exploded = spotify_df[['artists_upd','id']].explode('artists_upd')\n",
    "        artists_exploded_enriched = artists_exploded.merge(\n",
    "            data_w_genre, how='left', left_on='artists_upd', right_on='artists')\n",
    "        artists_exploded_enriched_nonnull = artists_exploded_enriched[~artists_exploded_enriched.genres_upd.isnull()]\n",
    "        artists_genres_consolidated = artists_exploded_enriched_nonnull.groupby('id')['genres_upd'].apply(list).reset_index()\n",
    "        artists_genres_consolidated['consolidates_genre_lists'] = artists_genres_consolidated['genres_upd'].apply(\n",
    "            lambda x: list(set(list(itertools.chain.from_iterable(x)))))\n",
    "        spotify_df = spotify_df.merge(\n",
    "            artists_genres_consolidated[['id','consolidates_genre_lists']], on='id', how='left')\n",
    "        spotify_df['year'] = spotify_df['release_date'].apply(lambda x: x.split('-')[0])\n",
    "        float_cols = spotify_df.dtypes[spotify_df.dtypes == 'float64'].index.values\n",
    "        spotify_df['popularity_red'] = spotify_df['popularity'].apply(lambda x: int(x/5))\n",
    "        spotify_df['genre'] = spotify_df['consolidates_genre_lists'].apply(\n",
    "            lambda d: d if isinstance(d, list) else [])\n",
    "        \n",
    "        # Feature Engineering\n",
    "        def ohe_prep(df, column, new_name): \n",
    "            tf_df = pd.get_dummies(df[column])\n",
    "            feature_names = tf_df.columns\n",
    "            tf_df.columns = [new_name + \"|\" + str(i) for i in feature_names]\n",
    "            tf_df.reset_index(drop=True, inplace=True)    \n",
    "            return tf_df\n",
    "        \n",
    "        # def create_feature_set(df, float_cols):\n",
    "        #     tfidf = TfidfVectorizer()\n",
    "        #     tfidf_matrix = tfidf.fit_transform(df['consolidates_genre_lists'].apply(lambda x: \" \".join(x)))\n",
    "        #     genre_df = pd.DataFrame(tfidf_matrix.toarray())\n",
    "        #     genre_df.columns = ['genre' + \"|\" + i for i in tfidf.get_feature_names_out()]\n",
    "        #     genre_df.reset_index(drop=True, inplace=True)\n",
    "        #     year_ohe = ohe_prep(df, 'year','year') * 0.5\n",
    "        #     popularity_ohe = ohe_prep(df, 'popularity_red','pop') * 0.15\n",
    "        #     floats = df[float_cols].reset_index(drop=True)\n",
    "        #     scaler = MinMaxScaler()\n",
    "        #     floats_scaled = pd.DataFrame(scaler.fit_transform(floats), columns=floats.columns) * 0.2\n",
    "        #     final = pd.concat([genre_df, floats_scaled, popularity_ohe, year_ohe], axis=1)\n",
    "        #     final['id'] = df['id'].values\n",
    "        #     return final\n",
    "        def create_feature_set(df, float_cols):\n",
    "            tfidf = TfidfVectorizer()\n",
    "            # Ensure 'consolidates_genre_lists' contains lists\n",
    "            df['consolidates_genre_lists'] = df['consolidates_genre_lists'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "            # Apply TF-IDF Vectorizer\n",
    "            tfidf_matrix = tfidf.fit_transform(df['consolidates_genre_lists'].apply(lambda x: \" \".join(x)))\n",
    "            genre_df = pd.DataFrame(tfidf_matrix.toarray())\n",
    "            genre_df.columns = ['genre' + \"|\" + i for i in tfidf.get_feature_names_out()]\n",
    "            genre_df.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            # One-Hot Encoding for 'year' and 'popularity_red'\n",
    "            year_ohe = ohe_prep(df, 'year', 'year') * 0.5\n",
    "            popularity_ohe = ohe_prep(df, 'popularity_red', 'pop') * 0.15\n",
    "            \n",
    "            # Scale float columns\n",
    "            floats = df[float_cols].reset_index(drop=True)\n",
    "            scaler = MinMaxScaler()\n",
    "            floats_scaled = pd.DataFrame(scaler.fit_transform(floats), columns=floats.columns) * 0.2\n",
    "            \n",
    "            # Concatenate all features\n",
    "            final = pd.concat([genre_df, floats_scaled, popularity_ohe, year_ohe], axis=1)\n",
    "            final['id'] = df['id'].values\n",
    "            return final\n",
    "\n",
    "\n",
    "        complete_feature_set = create_feature_set(spotify_df, float_cols=float_cols)\n",
    "        self.spotify_df = spotify_df\n",
    "        self.complete_feature_set = complete_feature_set\n",
    "\n",
    "    def create_necessary_outputs(self, playlist_ids):\n",
    "        playlist = pd.DataFrame()\n",
    "        for ix, song_id in enumerate(playlist_ids):\n",
    "            if song_id in self.spotify_df['id'].values:\n",
    "                song_data = self.spotify_df[self.spotify_df['id'] == song_id].iloc[0]\n",
    "                playlist.loc[ix, 'artist'] = song_data['artists_upd'][0]\n",
    "                playlist.loc[ix, 'name'] = song_data['name']\n",
    "                playlist.loc[ix, 'id'] = song_id\n",
    "                playlist.loc[ix, 'date_added'] = pd.to_datetime('today') - pd.Timedelta(days=ix)\n",
    "        playlist['date_added'] = pd.to_datetime(playlist['date_added'])\n",
    "        playlist = playlist[playlist['id'].isin(self.spotify_df['id'].values)].sort_values('date_added', ascending=False)\n",
    "        return playlist\n",
    "\n",
    "    def generate_playlist_feature(self, complete_feature_set, playlist_df, weight_factor=1.09):\n",
    "        complete_feature_set_playlist = complete_feature_set[complete_feature_set['id'].isin(playlist_df['id'].values)]\n",
    "        complete_feature_set_playlist = complete_feature_set_playlist.merge(\n",
    "            playlist_df[['id','date_added']], on='id', how='inner')\n",
    "        complete_feature_set_nonplaylist = complete_feature_set[~complete_feature_set['id'].isin(playlist_df['id'].values)]\n",
    "        playlist_feature_set = complete_feature_set_playlist.sort_values('date_added', ascending=False)\n",
    "        most_recent_date = playlist_feature_set.iloc[0]['date_added']\n",
    "        for ix, row in playlist_feature_set.iterrows():\n",
    "            playlist_feature_set.loc[ix,'months_from_recent'] = int((most_recent_date.to_pydatetime() - row['date_added'].to_pydatetime()).days / 30)\n",
    "        playlist_feature_set['weight'] = playlist_feature_set['months_from_recent'].apply(\n",
    "            lambda x: weight_factor ** (-x))\n",
    "        playlist_feature_set_weighted = playlist_feature_set.copy()\n",
    "        playlist_feature_set_weighted.update(\n",
    "            playlist_feature_set_weighted.iloc[:,:-4].mul(playlist_feature_set_weighted.weight, 0))\n",
    "        playlist_feature_set_weighted_final = playlist_feature_set_weighted.iloc[:, :-4]\n",
    "        return playlist_feature_set_weighted_final.sum(axis=0), complete_feature_set_nonplaylist\n",
    "\n",
    "    def generate_playlist_recos(self, features, nonplaylist_features, top_k=10):\n",
    "        non_playlist_df = self.spotify_df[self.spotify_df['id'].isin(nonplaylist_features['id'].values)]\n",
    "        non_playlist_df = non_playlist_df.reset_index(drop=True)\n",
    "        nonplaylist_features = nonplaylist_features.reset_index(drop=True)\n",
    "        non_playlist_df['sim'] = cosine_similarity(\n",
    "            nonplaylist_features.drop('id', axis=1).values, features.values.reshape(1, -1))[:,0]\n",
    "        non_playlist_df_top_k = non_playlist_df.sort_values('sim', ascending=False).head(top_k)\n",
    "        return non_playlist_df_top_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           id     artists_upd     name      sim\n",
      "27764  4t0OI7XrODjSkAu3bTPmWj  [Taylor Swift]  Fifteen  0.99909\n"
     ]
    }
   ],
   "source": [
    "##Example 1\n",
    "\n",
    "# Instantiate the model\n",
    "model = RecommendationModel()\n",
    "\n",
    "# Provide a list of song IDs from your dataset\n",
    "playlist_ids = ['6wn61Fzx9XMxQmieLpoIhW', '1D4PL9B8gOg78jiHg3FvBb', '5P4wWhUYWM0IaVYLuZxdar']\n",
    "\n",
    "# Create playlist dataframe\n",
    "playlist_df = model.create_necessary_outputs(playlist_ids)\n",
    "\n",
    "# Generate playlist feature vector and non-playlist features\n",
    "features, nonplaylist_features = model.generate_playlist_feature(model.complete_feature_set, playlist_df)\n",
    "\n",
    "# Generate recommendations with top_k=1 to get only the top recommendation\n",
    "recommendations = model.generate_playlist_recos(features, nonplaylist_features, top_k=1)\n",
    "\n",
    "# View the top recommendation\n",
    "print(recommendations[['id', 'artists_upd', 'name', 'sim']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m features, nonplaylist_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_playlist_feature(model\u001b[38;5;241m.\u001b[39mcomplete_feature_set, playlist_df)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Generate recommendations with top_k=1 to get only the top recommendation\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_playlist_recos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonplaylist_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# View the top recommendation\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(recommendations[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124martists_upd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msim\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "Cell \u001b[0;32mIn[3], line 123\u001b[0m, in \u001b[0;36mRecommendationModel.generate_playlist_recos\u001b[0;34m(self, features, nonplaylist_features, top_k)\u001b[0m\n\u001b[1;32m    121\u001b[0m non_playlist_df \u001b[38;5;241m=\u001b[39m non_playlist_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    122\u001b[0m nonplaylist_features \u001b[38;5;241m=\u001b[39m nonplaylist_features\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 123\u001b[0m non_playlist_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msim\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnonplaylist_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    125\u001b[0m non_playlist_df_top_k \u001b[38;5;241m=\u001b[39m non_playlist_df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msim\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(top_k)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m non_playlist_df_top_k\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1681\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m-> 1681\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n\u001b[1;32m   1683\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m X_normalized\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:1933\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     sparse_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1931\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m-> 1933\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe normalize function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1942\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/sklearn/utils/validation.py:119\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 119\u001b[0m     first_pass_isfinite \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39misfinite(\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:2485\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2482\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2486\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\n\u001b[1;32m   2488\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Example 2\n",
    "\n",
    "# Instantiate the model\n",
    "model = RecommendationModel()\n",
    "\n",
    "# Provide a list of song IDs from your dataset\n",
    "playlist_ids = ['7BqBn9nzAq8spo5e7cZ0dJ', '3RH9idbxUAMcUldet2ormp', '4HlFJV71xXKIGcU3kRyttv']\n",
    "\n",
    "# Create playlist dataframe\n",
    "playlist_df = model.create_necessary_outputs(playlist_ids)\n",
    "\n",
    "# Generate playlist feature vector and non-playlist features\n",
    "features, nonplaylist_features = model.generate_playlist_feature(model.complete_feature_set, playlist_df)\n",
    "\n",
    "# Generate recommendations with top_k=1 to get only the top recommendation\n",
    "recommendations = model.generate_playlist_recos(features, nonplaylist_features, top_k=1)\n",
    "\n",
    "# View the top recommendation\n",
    "print(recommendations[['id', 'artists_upd', 'name', 'sim']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           id              artists_upd  \\\n",
      "74321  2WsuSYJNXGKXVYkHPnq2yp  [Lil Tecca, Juice WRLD]   \n",
      "\n",
      "                                   name       sim  \n",
      "74321  Ransom (with Juice WRLD) - Remix  0.900897  \n"
     ]
    }
   ],
   "source": [
    "##Example 3\n",
    "\n",
    "# Instantiate the model\n",
    "model = RecommendationModel()\n",
    "\n",
    "# Provide a list of song IDs from your dataset\n",
    "playlist_ids = ['6Hj9jySrnFppAI0sEMCZpJ', '0nbXyq5TXYPCO7pr3N8S4I', '3eekarcy7kvN4yt5ZFzltW']\n",
    "\n",
    "# Create playlist dataframe\n",
    "playlist_df = model.create_necessary_outputs(playlist_ids)\n",
    "\n",
    "# Generate playlist feature vector and non-playlist features\n",
    "features, nonplaylist_features = model.generate_playlist_feature(model.complete_feature_set, playlist_df)\n",
    "\n",
    "# Generate recommendations with top_k=1 to get only the top recommendation\n",
    "recommendations = model.generate_playlist_recos(features, nonplaylist_features, top_k=1)\n",
    "\n",
    "# View the top recommendation\n",
    "print(recommendations[['id', 'artists_upd', 'name', 'sim']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            id  \\\n",
      "0       4BJqT0PrAfrxzMOxytFOIz   \n",
      "1       7xPhfUan2yNtyFG0cUWkt8   \n",
      "2       1o6I8BglA6ylDMrIELygv1   \n",
      "3       3ftBPsC5vPBKxYSee08FDH   \n",
      "4       4d6HGyGT8e121BsdKmw9v6   \n",
      "...                        ...   \n",
      "170648  0KkIkfsLEJbrcIhYsCL7L5   \n",
      "170649  0OStKKAuXlxA0fMH54Qs6E   \n",
      "170650  4BZXVFYCb76Q0Klojq4piV   \n",
      "170651  5SiZJoLXp3WOl3J4C8IK0d   \n",
      "170652  7HmnJHfs0BkFzX4x8j0hkl   \n",
      "\n",
      "                                                     name  \\\n",
      "0       Piano Concerto No. 3 in D Minor, Op. 30: III. ...   \n",
      "1                                 Clancy Lowered the Boom   \n",
      "2                                               Gati Bali   \n",
      "3                                               Danny Boy   \n",
      "4                             When Irish Eyes Are Smiling   \n",
      "...                                                   ...   \n",
      "170648                                              China   \n",
      "170649                        Halloweenie III: Seven Days   \n",
      "170650                                                AYA   \n",
      "170651                                           Darkness   \n",
      "170652                    Billetes Azules (with J Balvin)   \n",
      "\n",
      "                                                  artists  \n",
      "0       ['Sergei Rachmaninoff', 'James Levine', 'Berli...  \n",
      "1                                          ['Dennis Day']  \n",
      "2       ['KHP Kridhamardawa Karaton Ngayogyakarta Hadi...  \n",
      "3                                        ['Frank Parker']  \n",
      "4                                          ['Phil Regan']  \n",
      "...                                                   ...  \n",
      "170648  ['Anuel AA', 'Daddy Yankee', 'KAROL G', 'Ozuna...  \n",
      "170649                                       ['Ashnikko']  \n",
      "170650                                        ['MAMAMOO']  \n",
      "170651                                         ['Eminem']  \n",
      "170652                              ['KEVVO', 'J Balvin']  \n",
      "\n",
      "[170653 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print all song IDs\n",
    "spotify_df = pd.read_csv('data.csv')\n",
    "print(spotify_df[['id', 'name', 'artists']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
